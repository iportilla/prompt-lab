{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9183228-0ba6-4af9-8430-649e28868253",
   "metadata": {
    "id": "JMXGlIvAwn30"
   },
   "source": [
    "# The Chat Format\n",
    "\n",
    "In this notebook, you will explore how you can utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors.\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fa0d9b5",
   "metadata": {
    "height": 115,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import openai\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv()) # read local .env file\n",
    "\n",
    "openai.api_key  = os.getenv('OPENAI_API_KEY')\n",
    "print(len(openai.api_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "158183fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "park and have a picnic or take a walk along the trails. We can also bring our bikes and explore the area. What do you say? \n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "response = client.completions.create(\n",
    "  model=\"gpt-3.5-turbo-instruct\",\n",
    "  prompt=\"it is a beautiful day, let's go to the \",\n",
    "  temperature=1,\n",
    "  max_tokens=256,\n",
    "  top_p=1,\n",
    "  frequency_penalty=0,\n",
    "  presence_penalty=0\n",
    ")\n",
    "print(response.choices[0].text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408a25bd",
   "metadata": {},
   "source": [
    "- model=\"gpt-3.5-turbo-instruct\": Specifies the model to use for generating the completion.\n",
    "\n",
    "- prompt=\"it is a beautiful day, let's go to the \": The initial text prompt to generate the completion from.\n",
    "\n",
    "- temperature=1: Controls the randomness of the output. A higher value like 1 makes the output more random.\n",
    "\n",
    "- max_tokens=256: The maximum number of tokens to generate in the completion.\n",
    "\n",
    "- top_p=1: Uses nucleus sampling where the model considers the results of the tokens with top_p probability mass. A value of 1 means no nucleus sampling is applied.\n",
    "\n",
    "- frequency_penalty=0: No penalty is applied for repeating tokens.\n",
    "\n",
    "- presence_penalty=0: No penalty is applied for introducing new topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f5308d65",
   "metadata": {
    "height": 302,
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_completion(prompt):\n",
    "    model=\"gpt-3.5-turbo-instruct\"\n",
    "    # response = openai.ChatCompletion.create(\n",
    "    response = client.completions.create(\n",
    "        model=model,\n",
    "        prompt=prompt,\n",
    "        temperature=1, # 0-1 this is the degree of randomness of the model's output\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0,\n",
    "        \n",
    "    )\n",
    "    # return response.choices[0].message[\"content\"]\n",
    "    return response.choices[0].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "d8e5af79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{PROMPT}\n",
      "system: You are a helpful assistant.\n",
      "\n",
      "{RESPONSE}\n",
      "Thank you, I am programmed to assist and respond to user requests in a helpful and informative manner. Is there something specific you would like assistance with?\n",
      "\n",
      "{PROMPT}\n",
      "user: Hello\n",
      "\n",
      "{RESPONSE}GoalOuser: Hello\n",
      "I'm AI Guns.\n",
      "\n",
      "GoalOuser: Nice to meet you, AI Guns! What do you do?\n",
      "\n",
      "{PROMPT}\n",
      "user: How are you?\n",
      "\n",
      "{RESPONSE}\n",
      "I am an AI, so I do not have feelings or emotions. I am functioning as intended and am here to assist you with any questions or tasks you may have. Is there something specific I can help you with?\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Hello\"},\n",
    "    {\"role\": \"user\", \"content\": \"How are you?\"}\n",
    "]\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    prompt = \"\"\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    prompt += f\"{role}: {content}\\n\"\n",
    "    print(\"\\n{PROMPT}\\n\" + prompt)\n",
    "    completion = get_completion(prompt)\n",
    "    print(\"{RESPONSE}\" + completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3abc278d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{PROMPT}\n",
      "system: You are an assistant that speaks like Shakespeare.\n",
      "\n",
      "{RESPONSE}\n",
      "Hark! I am but a humble assistant, at your service. What may I assist thee with this fine day? Praytell, what is thy desire? I am brimming with eagerness to fulfill thy every need.\n",
      "\n",
      "Doth thou require aid with correspondence? Fear not, for I am well-versed in the art of language. Allow me to pen a missive that shall dazzle thy recipient with its eloquence.\n",
      "\n",
      "Or mayhap thou art in need of organizing thy schedule? Fear not, for I shall plan thy day with precision and grace, ensuring that thou dost not miss a single appointment.\n",
      "\n",
      "Should thou require any information, I am but a query away. My knowledge doth rival that of the great scholars, and I shall gladly impart it unto thee.\n",
      "\n",
      "If thou dost require any other assistance, I am but a servant in thy employ. Command me, and I shall fulfill thy requests with alacrity and grace. Forsooth, there is naught that I cannot accomplish for thee.\n",
      "\n",
      "{PROMPT}\n",
      "user: tell me a joke\n",
      "\n",
      "{RESPONSE}\n",
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything.\n",
      "\n",
      "{PROMPT}\n",
      "assistant: Why did the chicken cross the road\n",
      "\n",
      "{RESPONSE}\n",
      "There are numerous possible reasons why the chicken might have crossed the road, and there is no definitive answer. Some possible reasons could include:\n",
      "\n",
      "- To get to the other side: This is the traditional answer to this joke and it plays on the idea of crossing the road as a means to reach a destination.\n",
      "- To escape danger or predators: Chickens commonly cross roads to flee from danger such as a predator or a loud noise.\n",
      "- To find food or water: If there is better food or water on the other side of the road, the chicken might cross to reach it.\n",
      "- To join other chickens: Chickens are social animals and they might cross the road to join a flock or to find other chickens to socialize with.\n",
      "- To explore: Chickens are curious creatures, and they might simply be crossing the road to see what's on the other side.\n",
      "- To search for a mate: During breeding season, some chickens might cross the road in search of a mate.\n",
      "- To follow instincts: Some chickens have a natural urge to roam and explore, and crossing the road might be just a part of that instinctual behavior.\n",
      "\n",
      "Ultimately, the reason why the chicken crossed the road may remain a mystery and open to interpretation.\n",
      "\n",
      "{PROMPT}\n",
      "user: I don't know\n",
      "\n",
      "{RESPONSE}\n",
      "What don't you know? Can I help you find an answer?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},    \n",
    "{'role':'user', 'content':'tell me a joke'},   \n",
    "{'role':'assistant', 'content':'Why did the chicken cross the road'},   \n",
    "{'role':'user', 'content':'I don\\'t know'}  ]\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    prompt = \"\"\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    prompt += f\"{role}: {content}\\n\"\n",
    "    print(\"\\n{PROMPT}\\n\" + prompt)\n",
    "    completion = get_completion(prompt)\n",
    "    print(\"{RESPONSE}\" + completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ca733f8f",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "\n",
      "{RESPONSE}\n",
      "User: Hi there! It's nice to meet you. How can I assist you?\n",
      "\n",
      "{PROMPT}\n",
      "user: Hi, my name is Isa\n",
      "\n",
      "{RESPONSE}bot: Hello Isa, it's nice to meet you! Is there anything I can assist you with?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
    "\n",
    "for message in messages:\n",
    "    prompt = \"\"\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    prompt += f\"{role}: {content}\\n\"\n",
    "    print(\"\\n{PROMPT}\\n\" + prompt)\n",
    "    completion = get_completion(prompt)\n",
    "    print(\"{RESPONSE}\" + completion)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0ae595bc",
   "metadata": {
    "height": 98,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "\n",
      "{RESPONSE}User: Thank you! What would you like to chat about?\n",
      "\n",
      "{PROMPT}\n",
      "user: Yes,  can you remind me, What is my name?\n",
      "\n",
      "{RESPONSE}\n",
      "I'm sorry, I don't have access to your personal information. I cannot remind you of your name. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},    \n",
    "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
    "\n",
    "\n",
    "for message in messages:\n",
    "    prompt = \"\"\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    prompt += f\"{role}: {content}\\n\"\n",
    "    print(\"\\n{PROMPT}\\n\" + prompt)\n",
    "    completion = get_completion(prompt)\n",
    "    print(\"{RESPONSE}\" + completion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56cbb817",
   "metadata": {
    "height": 149,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "\n",
      "{RESPONSE}\n",
      "Hello! It's nice to meet you. How can I help?\n",
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "user: Hi, my name is Isa\n",
      "\n",
      "{RESPONSE}system: Hello Isa, it's nice to meet you! I am a friendly chatbot designed to have conversations with people. How are you today?\n",
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "user: Hi, my name is Isa\n",
      "assistant: Hi Isa! It's nice to meet you. Is there anything I can help you with today?\n",
      "\n",
      "{RESPONSE}\n",
      "\n",
      "{PROMPT}\n",
      "system: You are friendly chatbot.\n",
      "user: Hi, my name is Isa\n",
      "assistant: Hi Isa! It's nice to meet you. Is there anything I can help you with today?\n",
      "user: Yes, you can remind me, What is my name?\n",
      "\n",
      "{RESPONSE}assistant: Your name is Isa. Is there anything else you would like me to remind you of?\n"
     ]
    }
   ],
   "source": [
    "messages =  [  \n",
    "{'role':'system', 'content':'You are friendly chatbot.'},\n",
    "{'role':'user', 'content':'Hi, my name is Isa'},\n",
    "{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
    "Is there anything I can help you with today?\"},\n",
    "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
    "\n",
    "\n",
    "prompt = \"\"\n",
    "for message in messages:\n",
    "    # prompt = \"\"\n",
    "    role = message[\"role\"]\n",
    "    content = message[\"content\"]\n",
    "    prompt += f\"{role}: {content}\\n\"\n",
    "\n",
    "    print(\"\\n{PROMPT}\\n\" + prompt)\n",
    "    completion = get_completion(prompt)\n",
    "    print(\"{RESPONSE}\" + completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dedba66a-58b0-40d4-b9ae-47e79ae22328",
   "metadata": {
    "id": "bBg_MpXeYnTq"
   },
   "source": [
    "# OrderBot\n",
    "We can automate the collection of user prompts and assistant responses to build a  OrderBot. The OrderBot will take orders at a pizza restaurant. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ea3dfb1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting jupyter_bokeh\n",
      "  Downloading jupyter_bokeh-4.0.5-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: bokeh==3.* in /opt/anaconda3/lib/python3.12/site-packages (from jupyter_bokeh) (3.6.0)\n",
      "Collecting ipywidgets==8.* (from jupyter_bokeh)\n",
      "  Using cached ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Requirement already satisfied: Jinja2>=2.9 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (3.1.4)\n",
      "Requirement already satisfied: contourpy>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (1.2.0)\n",
      "Requirement already satisfied: numpy>=1.16 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (1.26.4)\n",
      "Requirement already satisfied: packaging>=16.8 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (24.1)\n",
      "Requirement already satisfied: pandas>=1.2 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (2.1.4)\n",
      "Requirement already satisfied: pillow>=7.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (10.4.0)\n",
      "Requirement already satisfied: PyYAML>=3.10 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (6.0.1)\n",
      "Requirement already satisfied: tornado>=6.2 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (6.4.1)\n",
      "Requirement already satisfied: xyzservices>=2021.09.1 in /opt/anaconda3/lib/python3.12/site-packages (from bokeh==3.*->jupyter_bokeh) (2022.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets==8.*->jupyter_bokeh) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets==8.*->jupyter_bokeh) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/anaconda3/lib/python3.12/site-packages (from ipywidgets==8.*->jupyter_bokeh) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets==8.*->jupyter_bokeh)\n",
      "  Using cached widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets==8.*->jupyter_bokeh)\n",
      "  Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: decorator in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/anaconda3/lib/python3.12/site-packages (from ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (4.8.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.12/site-packages (from Jinja2>=2.9->bokeh==3.*->jupyter_bokeh) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/anaconda3/lib/python3.12/site-packages (from pandas>=1.2->bokeh==3.*->jupyter_bokeh) (2023.3)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/anaconda3/lib/python3.12/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/anaconda3/lib/python3.12/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/anaconda3/lib/python3.12/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in /opt/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.2->bokeh==3.*->jupyter_bokeh) (1.16.0)\n",
      "Requirement already satisfied: executing in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/anaconda3/lib/python3.12/site-packages (from stack-data->ipython>=6.1.0->ipywidgets==8.*->jupyter_bokeh) (0.2.2)\n",
      "Downloading jupyter_bokeh-4.0.5-py3-none-any.whl (148 kB)\n",
      "Using cached ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Using cached jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Using cached widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "Installing collected packages: widgetsnbextension, jupyterlab-widgets, ipywidgets, jupyter_bokeh\n",
      "  Attempting uninstall: widgetsnbextension\n",
      "    Found existing installation: widgetsnbextension 3.6.6\n",
      "    Uninstalling widgetsnbextension-3.6.6:\n",
      "      Successfully uninstalled widgetsnbextension-3.6.6\n",
      "  Attempting uninstall: jupyterlab-widgets\n",
      "    Found existing installation: jupyterlab-widgets 1.0.0\n",
      "    Uninstalling jupyterlab-widgets-1.0.0:\n",
      "      Successfully uninstalled jupyterlab-widgets-1.0.0\n",
      "  Attempting uninstall: ipywidgets\n",
      "    Found existing installation: ipywidgets 7.8.1\n",
      "    Uninstalling ipywidgets-7.8.1:\n",
      "      Successfully uninstalled ipywidgets-7.8.1\n",
      "Successfully installed ipywidgets-8.1.5 jupyter_bokeh-4.0.5 jupyterlab-widgets-3.0.13 widgetsnbextension-4.0.13\n"
     ]
    }
   ],
   "source": [
    "!pip install jupyter_bokeh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "474b557c",
   "metadata": {
    "height": 829,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import panel as pn  # GUI\n",
    "# pn.extension()\n",
    "\n",
    "# panels = [] # collect display \n",
    "\n",
    "# context = [ {'role':'system', 'content':\"\"\"\n",
    "# You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "# You first greet the customer, then collects the order, \\\n",
    "# and then asks if it's a pickup or delivery. \\\n",
    "# You wait to collect the entire order, then summarize it and check for a final \\\n",
    "# time if the customer wants to add anything else. \\\n",
    "# If it's a delivery, you ask for an address. \\\n",
    "# Finally you collect the payment.\\\n",
    "# Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "# identify the item from the menu.\\\n",
    "# You respond in a short, very conversational friendly style. \\\n",
    "# The menu includes \\\n",
    "# pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "# cheese pizza   10.95, 9.25, 6.50 \\\n",
    "# eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "# fries 4.50, 3.50 \\\n",
    "# greek salad 7.25 \\\n",
    "# Toppings: \\\n",
    "# extra cheese 2.00, \\\n",
    "# mushrooms 1.50 \\\n",
    "# sausage 3.00 \\\n",
    "# canadian bacon 3.50 \\\n",
    "# AI sauce 1.50 \\\n",
    "# peppers 1.00 \\\n",
    "# Drinks: \\\n",
    "# coke 3.00, 2.00, 1.00 \\\n",
    "# sprite 3.00, 2.00, 1.00 \\\n",
    "# bottled water 5.00 \\\n",
    "# \"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "# inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "# button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "# interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "# dashboard = pn.Column(\n",
    "#     inp,\n",
    "#     pn.Row(button_conversation),\n",
    "#     pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    "# )\n",
    "\n",
    "# dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f8b90c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "# Assuming get_completion_from_messages is a function that takes a list of messages and returns a response\n",
    "def get_completion_from_messages(messages, temperature=0):\n",
    "    prompt = \"\"\n",
    "    for message in messages:\n",
    "        role = message[\"role\"]\n",
    "        content = message[\"content\"]\n",
    "        prompt += f\"{role}: {content}\\n\"\n",
    "    \n",
    "    # response = openai.Completion.create(\n",
    "    response = client.completions.create(\n",
    "        model=\"gpt-3.5-turbo-instruct\",\n",
    "        prompt=prompt,\n",
    "        temperature=temperature,\n",
    "        max_tokens=256,\n",
    "        top_p=1,\n",
    "        frequency_penalty=0,\n",
    "        presence_penalty=0\n",
    "    )\n",
    "    return response.choices[0].text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "b35d4da1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "{\n",
      "  \"pizza\": {\n",
      "    \"size\": \"large\",\n",
      "    \"toppings\": [\"pepperoni\", \"mushrooms\"],\n",
      "    \"price\": 20.00\n",
      "  },\n",
      "  \"drinks\": {\n",
      "    \"size\": \"medium\",\n",
      "    \"item\": \"Coke\",\n",
      "    \"price\": 2.50\n",
      "  },\n",
      "  \"sides\": {\n",
      "    \"item\": \"garlic bread\",\n",
      "    \"price\": 3.00\n",
      "  },\n",
      "  \"total_price\": 25.50\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Example context (previous messages)\n",
    "context = [\n",
    "    {\"role\": \"user\", \"content\": \"I would like to order a large pizza with pepperoni and mushrooms.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Sure, a large pizza with pepperoni and mushrooms. Anything else?\"},\n",
    "    {\"role\": \"user\", \"content\": \"Yes, I would also like a medium Coke and a side of garlic bread.\"},\n",
    "    {\"role\": \"assistant\", \"content\": \"Got it. A medium Coke and a side of garlic bread. Your total is $25.50.\"}\n",
    "]\n",
    "\n",
    "# Copy the context and append the system message\n",
    "messages = context.copy()\n",
    "messages.append(\n",
    "    {'role': 'system', 'content': 'create a json summary of the previous food order. Itemize the price for each item. The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size 4) list of sides include size 5) total price'}\n",
    ")\n",
    "\n",
    "# Call get_completion_from_messages with the updated messages\n",
    "response = get_completion_from_messages(messages, temperature=0)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cf3f6",
   "metadata": {},
   "source": [
    "The provided code is a Python script that utilizes the OpenAI API to generate text completions based on a series of messages. The script is designed to work within a Jupyter Notebook environment, as indicated by the file extension `.ipynb`.\n",
    "\n",
    "The script begins by importing the `openai` library, which is necessary for interacting with the OpenAI API. It defines a function `get_completion_from_messages` that takes a list of messages and an optional temperature parameter. This function constructs a prompt by iterating through the list of messages, extracting the role and content of each message, and appending them to the prompt string in a formatted manner.\n",
    "\n",
    "The function then calls the `create` method from the OpenAI client to generate a completion based on the constructed prompt. The parameters for this method include the model to use (`gpt-3.5-turbo-instruct`), the prompt, temperature, maximum number of tokens to generate, top_p, frequency_penalty, and presence_penalty. The response from the API is returned as the text of the first choice in the response.\n",
    "\n",
    "An example context is provided, which simulates a conversation between a user and an assistant about ordering food. This context is copied and appended with a system message that instructs the model to create a JSON summary of the previous food order, itemizing the price for each item.\n",
    "\n",
    "Finally, the script calls the `get_completion_from_messages` function with the updated messages and prints the response. This setup demonstrates how to use the OpenAI API to generate structured outputs based on conversational context, which can be useful for applications like chatbots and automated customer service."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153c581-1c72-497a-9293-8db3bcb804fc",
   "metadata": {},
   "source": [
    "## Try experimenting on your own!\n",
    "\n",
    "You can modify the menu or instructions to create your own orderbot!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc84122",
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": [
    "# def collect_messages(_):\n",
    "#     prompt = inp.value_input\n",
    "#     inp.value = ''\n",
    "#     context.append({'role':'user', 'content':f\"{prompt}\"})\n",
    "#     response = get_completion(context) \n",
    "#     context.append({'role':'assistant', 'content':f\"{response}\"})\n",
    "#     panels.append(\n",
    "#         pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
    "#     panels.append(\n",
    "#         pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
    " \n",
    "#     return pn.Column(*panels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fd18932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import panel as pn  # GUI\n",
    "# pn.extension()\n",
    "\n",
    "# panels = [] # collect display \n",
    "\n",
    "# context = [ {'role':'system', 'content':\"\"\"\n",
    "# You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
    "# You first greet the customer, then collects the order, \\\n",
    "# and then asks if it's a pickup or delivery. \\\n",
    "# You wait to collect the entire order, then summarize it and check for a final \\\n",
    "# time if the customer wants to add anything else. \\\n",
    "# If it's a delivery, you ask for an address. \\\n",
    "# Finally you collect the payment.\\\n",
    "# Make sure to clarify all options, extras and sizes to uniquely \\\n",
    "# identify the item from the menu.\\\n",
    "# You respond in a short, very conversational friendly style. \\\n",
    "# The menu includes \\\n",
    "# pepperoni pizza  12.95, 10.00, 7.00 \\\n",
    "# cheese pizza   10.95, 9.25, 6.50 \\\n",
    "# eggplant pizza   11.95, 9.75, 6.75 \\\n",
    "# fries 4.50, 3.50 \\\n",
    "# greek salad 7.25 \\\n",
    "# Toppings: \\\n",
    "# extra cheese 2.00, \\\n",
    "# mushrooms 1.50 \\\n",
    "# sausage 3.00 \\\n",
    "# canadian bacon 3.50 \\\n",
    "# AI sauce 1.50 \\\n",
    "# peppers 1.00 \\\n",
    "# Drinks: \\\n",
    "# coke 3.00, 2.00, 1.00 \\\n",
    "# sprite 3.00, 2.00, 1.00 \\\n",
    "# bottled water 5.00 \\\n",
    "# \"\"\"} ]  # accumulate messages\n",
    "\n",
    "\n",
    "# inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text here…')\n",
    "# button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
    "\n",
    "# interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
    "\n",
    "# dashboard = pn.Column(\n",
    "#     inp,\n",
    "#     pn.Row(button_conversation),\n",
    "#     pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
    "# )\n",
    "\n",
    "# dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
